{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected resolution for a distance of 5 NM is: 5\n",
      "Number of rows as input: (24893, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quintengoens/Repos/close-encounters/.conda/lib/python3.12/site-packages/tempo/utils.py:122: ResampleWarning: \n",
      "            Resample Metrics Warning:\n",
      "                Earliest Timestamp: 2024-07-01 12:05:00\n",
      "                Latest Timestamp: 2024-07-01 12:10:00\n",
      "                No. of Unique Partitions: 2828\n",
      "                Resampled Min No. Values in Single a Partition: 1.0\n",
      "                Resampled Max No. Values in Single a Partition: 61.0\n",
      "                Resampled P25 No. Values in Single a Partition: 52.0\n",
      "                Resampled P50 No. Values in Single a Partition: 55.0\n",
      "                Resampled P75 No. Values in Single a Partition: 56.0\n",
      "                Resampled Total No. Values Across All Partitions: 145432.0\n",
      "        \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after resamplin and interpolating: 145432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs (raw): 118648\n",
      "Number of pairs after time filter 118648\n",
      "Number of pairs after FL filter 11077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/07 16:55:58 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique ID pairs: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from CloseEncountersH3 import *\n",
    "from CloseEncountersBF import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CloseEncountersH3\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.rpc.message.maxSize\", 1028) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "coords_df = pd.read_parquet('~/Repos/close-encounters/data/flight_profiles_cpf_20240701_filtered.parquet')\n",
    "f = np.logical_and(coords_df.TIME_OVER >= datetime(2024,7,1,12,5,0), coords_df.TIME_OVER<= datetime(2024,7,1,12,10,0))\n",
    "coords_df = coords_df[f]\n",
    "\n",
    "ce_h3_df = CloseEncountersH3(coords_df, distance_nm = 5, FL_diff = 9, FL_min = 250, deltaT_min = 10, spark = spark)\n",
    "\n",
    "#ce_bf_df = CloseEncountersBF(coords_df, distance_nm = 5, FL_diff = 9, FL_min = 250, deltaT_min = 10, spark = spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>time_over</th>\n",
       "      <th>h3_group</th>\n",
       "      <th>ID</th>\n",
       "      <th>lat1</th>\n",
       "      <th>lon1</th>\n",
       "      <th>time1</th>\n",
       "      <th>flight_lvl1</th>\n",
       "      <th>flight_id1</th>\n",
       "      <th>lat2</th>\n",
       "      <th>lon2</th>\n",
       "      <th>time2</th>\n",
       "      <th>flight_lvl2</th>\n",
       "      <th>flight_id2</th>\n",
       "      <th>time_diff_s</th>\n",
       "      <th>FL_diff</th>\n",
       "      <th>distance_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179908034</td>\n",
       "      <td>17179897081</td>\n",
       "      <td>2024-07-01 12:06:15</td>\n",
       "      <td>851e34cbfffffff</td>\n",
       "      <td>17179897081_17179908034</td>\n",
       "      <td>50.221343</td>\n",
       "      <td>12.152176</td>\n",
       "      <td>2024-07-01 12:06:15</td>\n",
       "      <td>369.166667</td>\n",
       "      <td>273710082.0</td>\n",
       "      <td>50.222153</td>\n",
       "      <td>12.137917</td>\n",
       "      <td>2024-07-01 12:06:15</td>\n",
       "      <td>360.250</td>\n",
       "      <td>273711122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>0.550529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17179908033</td>\n",
       "      <td>17179897080</td>\n",
       "      <td>2024-07-01 12:06:10</td>\n",
       "      <td>851fa9affffffff</td>\n",
       "      <td>17179897080_17179908033</td>\n",
       "      <td>50.232685</td>\n",
       "      <td>12.151574</td>\n",
       "      <td>2024-07-01 12:06:10</td>\n",
       "      <td>369.333333</td>\n",
       "      <td>273710082.0</td>\n",
       "      <td>50.219618</td>\n",
       "      <td>12.154236</td>\n",
       "      <td>2024-07-01 12:06:10</td>\n",
       "      <td>360.375</td>\n",
       "      <td>273711122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.958333</td>\n",
       "      <td>0.792061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17179908035</td>\n",
       "      <td>17179897082</td>\n",
       "      <td>2024-07-01 12:06:20</td>\n",
       "      <td>851fa9affffffff</td>\n",
       "      <td>17179897082_17179908035</td>\n",
       "      <td>50.210000</td>\n",
       "      <td>12.152778</td>\n",
       "      <td>2024-07-01 12:06:20</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>273710082.0</td>\n",
       "      <td>50.224687</td>\n",
       "      <td>12.121597</td>\n",
       "      <td>2024-07-01 12:06:20</td>\n",
       "      <td>360.125</td>\n",
       "      <td>273711122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.875000</td>\n",
       "      <td>1.489129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID2          ID1           time_over         h3_group  \\\n",
       "0  17179908034  17179897081 2024-07-01 12:06:15  851e34cbfffffff   \n",
       "1  17179908033  17179897080 2024-07-01 12:06:10  851fa9affffffff   \n",
       "2  17179908035  17179897082 2024-07-01 12:06:20  851fa9affffffff   \n",
       "\n",
       "                        ID       lat1       lon1               time1  \\\n",
       "0  17179897081_17179908034  50.221343  12.152176 2024-07-01 12:06:15   \n",
       "1  17179897080_17179908033  50.232685  12.151574 2024-07-01 12:06:10   \n",
       "2  17179897082_17179908035  50.210000  12.152778 2024-07-01 12:06:20   \n",
       "\n",
       "   flight_lvl1   flight_id1       lat2       lon2               time2  \\\n",
       "0   369.166667  273710082.0  50.222153  12.137917 2024-07-01 12:06:15   \n",
       "1   369.333333  273710082.0  50.219618  12.154236 2024-07-01 12:06:10   \n",
       "2   369.000000  273710082.0  50.224687  12.121597 2024-07-01 12:06:20   \n",
       "\n",
       "   flight_lvl2   flight_id2  time_diff_s   FL_diff  distance_nm  \n",
       "0      360.250  273711122.0            0  8.916667     0.550529  \n",
       "1      360.375  273711122.0            0  8.958333     0.792061  \n",
       "2      360.125  273711122.0            0  8.875000     1.489129  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_h3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID</th>\n",
       "      <th>lat1</th>\n",
       "      <th>lon1</th>\n",
       "      <th>time1</th>\n",
       "      <th>flight_lvl1</th>\n",
       "      <th>flight_id1</th>\n",
       "      <th>lat2</th>\n",
       "      <th>lon2</th>\n",
       "      <th>time2</th>\n",
       "      <th>flight_lvl2</th>\n",
       "      <th>flight_id2</th>\n",
       "      <th>time_diff_s</th>\n",
       "      <th>FL_diff</th>\n",
       "      <th>distance_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17179908033</td>\n",
       "      <td>17179897080</td>\n",
       "      <td>17179897080_17179908033</td>\n",
       "      <td>50.232685</td>\n",
       "      <td>12.151574</td>\n",
       "      <td>2024-07-01 12:06:10</td>\n",
       "      <td>369.333333</td>\n",
       "      <td>273710082.0</td>\n",
       "      <td>50.219618</td>\n",
       "      <td>12.154236</td>\n",
       "      <td>2024-07-01 12:06:10</td>\n",
       "      <td>360.375</td>\n",
       "      <td>273711122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.958333</td>\n",
       "      <td>0.792061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17179908035</td>\n",
       "      <td>17179897082</td>\n",
       "      <td>17179897082_17179908035</td>\n",
       "      <td>50.210000</td>\n",
       "      <td>12.152778</td>\n",
       "      <td>2024-07-01 12:06:20</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>273710082.0</td>\n",
       "      <td>50.224687</td>\n",
       "      <td>12.121597</td>\n",
       "      <td>2024-07-01 12:06:20</td>\n",
       "      <td>360.125</td>\n",
       "      <td>273711122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.875000</td>\n",
       "      <td>1.489129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17179908034</td>\n",
       "      <td>17179897081</td>\n",
       "      <td>17179897081_17179908034</td>\n",
       "      <td>50.221343</td>\n",
       "      <td>12.152176</td>\n",
       "      <td>2024-07-01 12:06:15</td>\n",
       "      <td>369.166667</td>\n",
       "      <td>273710082.0</td>\n",
       "      <td>50.222153</td>\n",
       "      <td>12.137917</td>\n",
       "      <td>2024-07-01 12:06:15</td>\n",
       "      <td>360.250</td>\n",
       "      <td>273711122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>0.550529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID2          ID1                       ID       lat1       lon1  \\\n",
       "0  17179908033  17179897080  17179897080_17179908033  50.232685  12.151574   \n",
       "1  17179908035  17179897082  17179897082_17179908035  50.210000  12.152778   \n",
       "2  17179908034  17179897081  17179897081_17179908034  50.221343  12.152176   \n",
       "\n",
       "                time1  flight_lvl1   flight_id1       lat2       lon2  \\\n",
       "0 2024-07-01 12:06:10   369.333333  273710082.0  50.219618  12.154236   \n",
       "1 2024-07-01 12:06:20   369.000000  273710082.0  50.224687  12.121597   \n",
       "2 2024-07-01 12:06:15   369.166667  273710082.0  50.222153  12.137917   \n",
       "\n",
       "                time2  flight_lvl2   flight_id2  time_diff_s   FL_diff  \\\n",
       "0 2024-07-01 12:06:10      360.375  273711122.0            0  8.958333   \n",
       "1 2024-07-01 12:06:20      360.125  273711122.0            0  8.875000   \n",
       "2 2024-07-01 12:06:15      360.250  273711122.0            0  8.916667   \n",
       "\n",
       "   distance_nm  \n",
       "0     0.792061  \n",
       "1     1.489129  \n",
       "2     0.550529  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_bf_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Imports\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# PySpark libraries\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import (\n",
    "    udf, col, explode, radians,\n",
    "    sin, cos, sqrt, atan2, lit, monotonically_increasing_id\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    StringType, ArrayType )\n",
    "from pyspark.sql import Window\n",
    "from tempo import *\n",
    "\n",
    "# Data libraries\n",
    "import h3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom libraries\n",
    "from helpers import select_resolution\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Spark Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CloseEncountersH3\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.rpc.message.maxSize\", 1028) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Close encounter parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "# Minimal horizontal distance before close encounter (NM)\n",
    "distance_nm = 5\n",
    "\n",
    "# Minimal vertical distance before close encounter (flight levels - FL)\n",
    "FL_diff = 9\n",
    "\n",
    "# The minimum flight level for assessment of the trajectory (lower sections are not analyzed)\n",
    "FL_min = 250\n",
    "\n",
    "# The maximum period we should interpolate in case of missing state-vectors (deltaT in minutes)\n",
    "deltaT_min = 10\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Default / Automatic parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "def h3_encounter(coords_df, distance_nm = 5, FL_diff = 9, FL_min = 250, deltaT_min = 10, spark = None):\n",
    "    resolution = select_resolution(distance_nm)\n",
    "    earth_radius_km = 6378\n",
    "    print(f\"The selected resolution for a distance of {distance_nm} NM is: {resolution}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Load and Filter Data\n",
    "    # -----------------------------------------------------------------------------\n",
    "    coords_df = coords_df[coords_df.FLIGHT_LEVEL > FL_min]\n",
    "    coords_df = coords_df[['FLIGHT_ID', 'LONGITUDE', 'LATITUDE', 'TIME_OVER', 'FLIGHT_LEVEL']].rename(\n",
    "        columns={\n",
    "            'LATITUDE': 'latitude', \n",
    "            'LONGITUDE': 'longitude'\n",
    "            }\n",
    "        )\n",
    "    coords_df.columns = [x.lower() for x in coords_df.columns]\n",
    "\n",
    "    print(f\"Number of rows as input: {coords_df.shape}\")\n",
    "    coords_df = spark.createDataFrame(coords_df)\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Resample and interpolate\n",
    "    # -----------------------------------------------------------------------------\n",
    "\n",
    "    coords_df = TSDF(coords_df, ts_col=\"time_over\", partition_cols = [\"flight_id\"])\n",
    "    coords_df = coords_df.resample(freq=\"5 sec\", func=\"mean\").interpolate(method='linear', freq=\"5 sec\", show_interpolated = True).df\n",
    "    coords_df = coords_df.repartition(100, [\"flight_id\"])\n",
    "    print(f\"Number of rows after resamplin and interpolating: {coords_df.count()}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Delete resampled periods which are longer than DeltaT = 10 min\n",
    "    # -----------------------------------------------------------------------------\n",
    "\n",
    "    # Define a window partitioned by flight and segment and ordered by time\n",
    "    w = Window.partitionBy(\"flight_id\").orderBy(\"time_over\")\n",
    "\n",
    "    # Flag changes in interpolation status (start of new group)\n",
    "    coords_df = coords_df.withColumn(\n",
    "        \"interpolation_group_change\",\n",
    "        (F.col(\"is_ts_interpolated\") != F.lag(\"is_ts_interpolated\", 1).over(w)).cast(\"int\")\n",
    "    )\n",
    "\n",
    "    # Fill nulls in the first row with 1 (new group)\n",
    "    coords_df = coords_df.withColumn(\n",
    "        \"interpolation_group_change\",\n",
    "        F.when(F.col(\"interpolation_group_change\").isNull(), 1).otherwise(F.col(\"interpolation_group_change\"))\n",
    "    )\n",
    "\n",
    "    # Create a cumulative sum over the changes to assign group IDs\n",
    "    coords_df = coords_df.withColumn(\n",
    "        \"interpolation_group_id\",\n",
    "        F.sum(\"interpolation_group_change\").over(w)\n",
    "    )\n",
    "\n",
    "    # Add min and max timestamp per interpolation group\n",
    "    group_window = Window.partitionBy(\"flight_id\", \"interpolation_group_id\")\n",
    "\n",
    "    coords_df = coords_df.withColumn(\"group_start_time\", F.min(\"time_over\").over(group_window))\n",
    "    coords_df = coords_df.withColumn(\"group_end_time\", F.max(\"time_over\").over(group_window))\n",
    "\n",
    "    # Calculate duration in seconds for each interpolation group\n",
    "    coords_df = coords_df.withColumn(\n",
    "        \"interpolation_group_duration_sec\",\n",
    "        F.col(\"group_end_time\").cast(\"long\") - F.col(\"group_start_time\").cast(\"long\")\n",
    "    )\n",
    "\n",
    "    # Filter logic:\n",
    "    # - If not interpolated, keep\n",
    "    # - If interpolated, keep only if group duration <= deltaT_min * 60 seconds\n",
    "    coords_df = coords_df.filter(\n",
    "        (~F.col(\"is_ts_interpolated\")) |\n",
    "        ((F.col(\"is_ts_interpolated\")) & (F.col(\"interpolation_group_duration_sec\") <= deltaT_min*60))\n",
    "    )\n",
    "\n",
    "    # Drop helper columns\n",
    "    coords_df = coords_df.drop(\"interpolation_group_change\", \"interpolation_group_id\",\n",
    "                            \"group_start_time\", \"group_end_time\", \"interpolation_group_duration_sec\")\n",
    "\n",
    "    # Add a segment ID\n",
    "    coords_df = coords_df.withColumn(\"segment_id\", monotonically_increasing_id())\n",
    "    coords_df = coords_df.repartition(100, [\"flight_id\", \"segment_id\"])\n",
    "\n",
    "    #coords_df = coords_df.filter(col('time_over')==datetime(2024,7,1,12,1,0))\n",
    "    coords_df.cache()\n",
    "    coords_df.count()\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Define UDFs for H3\n",
    "    # -----------------------------------------------------------------------------\n",
    "    def lat_lon_to_h3(lat, lon, resolution):\n",
    "        return h3.latlng_to_cell(lat, lon, resolution)\n",
    "\n",
    "    def grid_disk_k1(cell):\n",
    "        return h3.grid_disk(cell, k=1)\n",
    "\n",
    "    lat_lon_to_h3_udf = udf(lat_lon_to_h3, StringType())\n",
    "    grid_disk_k1_udf = udf(grid_disk_k1, ArrayType(StringType()))\n",
    "\n",
    "    # Add H3 index and neighbors\n",
    "    coords_df = coords_df.withColumn(\"h3_index\", lat_lon_to_h3_udf(col(\"latitude\"), col(\"longitude\"), lit(resolution)))\n",
    "    coords_df = coords_df.withColumn(\"h3_neighbours\", grid_disk_k1_udf(col(\"h3_index\")))\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Explode neighbors and group by time_over and h3_neighbour to collect IDs when there's multiple FLIGHT_ID in a cell\n",
    "    # -----------------------------------------------------------------------------\n",
    "    exploded_df = coords_df.withColumn(\"h3_neighbour\", explode(col(\"h3_neighbours\")))\n",
    "\n",
    "    grouped_df = (exploded_df.groupBy([\"time_over\", \"h3_neighbour\"])\n",
    "                .agg(F.countDistinct(\"flight_id\").alias(\"flight_count\"),\n",
    "                    F.collect_list(\"segment_id\").alias(\"id_list\"))\n",
    "                .filter(F.col(\"flight_count\") > 1)\n",
    "                .drop(\"flight_count\"))\n",
    "\n",
    "    grouped_df = grouped_df.filter(F.size(\"id_list\") > 1)\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Create pairwise combinations using self-join on indexed exploded DataFrame\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Explode id_list to individual rows and add index within each h3 group\n",
    "    df_exploded = grouped_df.withColumn(\"segment_id\", explode(\"id_list\")).drop('id_list')\n",
    "    window_spec = Window.partitionBy([\"time_over\",\"h3_neighbour\"]).orderBy(\"segment_id\")\n",
    "    df_indexed = df_exploded.withColumn(\"idx\", F.row_number().over(window_spec))\n",
    "\n",
    "    # Self-join to form unique unordered ID pairs\n",
    "    df_pairs = (\n",
    "        df_indexed.alias(\"df1\")\n",
    "        .join(\n",
    "            df_indexed.alias(\"df2\"),\n",
    "            (F.col(\"df1.time_over\") == F.col(\"df2.time_over\")) &\n",
    "            (F.col(\"df1.h3_neighbour\") == F.col(\"df2.h3_neighbour\")) &\n",
    "            (F.col(\"df1.idx\") < F.col(\"df2.idx\"))\n",
    "        )\n",
    "        .select(\n",
    "            F.col(\"df1.time_over\").alias(\"time_over\"),\n",
    "            F.col(\"df1.h3_neighbour\").alias(\"h3_group\"),\n",
    "            F.col(\"df1.segment_id\").alias(\"ID1\"),\n",
    "            F.col(\"df2.segment_id\").alias(\"ID2\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Clean Pairs, Create Unique Pair ID\n",
    "    # -----------------------------------------------------------------------------\n",
    "    df_pairs = df_pairs.filter(col(\"ID1\") != col(\"ID2\")) # should not be necessary as we join on < not <=\n",
    "    df_pairs = df_pairs.withColumn(\n",
    "        \"ID\",\n",
    "        F.concat_ws(\"_\", F.array_sort(F.array(col(\"ID1\"), col(\"ID2\"))))\n",
    "    )\n",
    "\n",
    "    # Define a window partitioned by ID, ordering arbitrarily (or by some column if needed)\n",
    "    window_spec = Window.partitionBy(\"ID\").orderBy(F.monotonically_increasing_id())\n",
    "\n",
    "    # Add row number to each partition\n",
    "    df_pairs = df_pairs.withColumn(\"row_num\", F.row_number().over(window_spec))\n",
    "\n",
    "    # Keep only the first row per ID\n",
    "    df_pairs = df_pairs.filter(F.col(\"row_num\") == 1).drop(\"row_num\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Join with Original Coordinates for Each ID\n",
    "    # -----------------------------------------------------------------------------\n",
    "    coords_sdf1 = coords_df.withColumnRenamed(\"segment_id\", \"ID1\") \\\n",
    "        .withColumnRenamed(\"latitude\", \"lat1\") \\\n",
    "        .withColumnRenamed(\"longitude\", \"lon1\") \\\n",
    "        .withColumnRenamed(\"time_over\", \"time1\") \\\n",
    "        .withColumnRenamed(\"flight_level\", 'flight_lvl1') \\\n",
    "        .withColumnRenamed(\"flight_id\", \"flight_id1\") \\\n",
    "        .select(\"ID1\", \"lat1\", \"lon1\", \"time1\", \"flight_lvl1\", \"flight_id1\")\n",
    "\n",
    "    coords_sdf2 = coords_df.withColumnRenamed(\"segment_id\", \"ID2\") \\\n",
    "        .withColumnRenamed(\"latitude\", \"lat2\") \\\n",
    "        .withColumnRenamed(\"longitude\", \"lon2\") \\\n",
    "        .withColumnRenamed(\"time_over\", \"time2\") \\\n",
    "        .withColumnRenamed(\"flight_level\", 'flight_lvl2') \\\n",
    "        .withColumnRenamed(\"flight_id\", \"flight_id2\") \\\n",
    "        .select(\"ID2\", \"lat2\", \"lon2\", \"time2\", \"flight_lvl2\", \"flight_id2\")\n",
    "\n",
    "    coords_sdf1 = coords_sdf1.repartition(100, \"ID1\")\n",
    "    coords_sdf2 = coords_sdf2.repartition(100, \"ID2\")\n",
    "\n",
    "    df_pairs = df_pairs.join(coords_sdf1, on=\"ID1\", how=\"left\")\n",
    "    df_pairs = df_pairs.join(coords_sdf2, on=\"ID2\", how=\"left\")\n",
    "    df_pairs.cache()\n",
    "    print(f\"Number of pairs (raw): {df_pairs.count()}\")\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Calculate and filter based on time differense (s)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    df_pairs = df_pairs.withColumn('time_diff_s', F.unix_timestamp(F.col(\"time1\")) - F.unix_timestamp(F.col(\"time2\")))\n",
    "    df_pairs = df_pairs.filter(F.abs(F.col('time_diff_s')) == 0)\n",
    "    df_pairs.cache()\n",
    "    print(f\"Number of pairs after time filter {df_pairs.count()}\")\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Calculate and filter based on height differense (s)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    df_pairs = df_pairs.withColumn('FL_diff', F.col(\"flight_lvl1\") - F.col(\"flight_lvl2\"))\n",
    "    df_pairs = df_pairs.filter(F.abs(F.col('FL_diff')) < lit(FL_diff))\n",
    "    df_pairs.cache()\n",
    "    print(f\"Number of pairs after FL filter {df_pairs.count()}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Calulate and filter based on distance (km)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    df_pairs.cache()\n",
    "    df_pairs = df_pairs.withColumn(\n",
    "        \"distance_nm\",\n",
    "        0.539957 * 2 * earth_radius_km * atan2(\n",
    "            sqrt(\n",
    "                (sin(radians(col(\"lat2\")) - radians(col(\"lat1\"))) / 2)**2 +\n",
    "                cos(radians(col(\"lat1\"))) * cos(radians(col(\"lat2\"))) *\n",
    "                (sin(radians(col(\"lon2\")) - radians(col(\"lon1\"))) / 2)**2\n",
    "            ),\n",
    "            sqrt(1 - (\n",
    "                (sin(radians(col(\"lat2\")) - radians(col(\"lat1\"))) / 2)**2 +\n",
    "                cos(radians(col(\"lat1\"))) * cos(radians(col(\"lat2\"))) *\n",
    "                (sin(radians(col(\"lon2\")) - radians(col(\"lon1\"))) / 2)**2\n",
    "            ))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_pairs = df_pairs.filter(col('distance_nm') <= lit(distance_nm))\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Fetch sample\n",
    "    # -----------------------------------------------------------------------------\n",
    "\n",
    "    df_pairs.cache()\n",
    "    df = df_pairs.toPandas()\n",
    "    print(f\"Number of unique ID pairs: {df_pairs.count()}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "max_distance = np.sqrt(3)/2*10.837435124897937*4\n",
    "fig = px.histogram(df, x='distance_nm')\n",
    "\n",
    "fig.add_vline(x=max_distance, line_dash = 'dash', line_color = 'firebrick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df = pd.read_parquet('~/Repos/close-encounters/data/flight_profiles_cpf_20240701_filtered.parquet')\n",
    "coords_df['SEGMENT_ID'] = coords_df.index\n",
    "coords_df = coords_df[coords_df.FLIGHT_LEVEL > 250]\n",
    "coords_df = coords_df[['FLIGHT_ID', 'SEGMENT_ID', 'LONGITUDE', 'LATITUDE', 'TIME_OVER', 'FLIGHT_LEVEL', 'AIRCRAFT_TYPE']].rename(\n",
    "    columns={\n",
    "        'LATITUDE': 'latitude', \n",
    "        'LONGITUDE': 'longitude'\n",
    "        }\n",
    "    )\n",
    "\n",
    "c1 = coords_df[['FLIGHT_ID', 'SEGMENT_ID', 'AIRCRAFT_TYPE']].rename(\n",
    "    {'FLIGHT_ID':'FLIGHT_ID1', 'SEGMENT_ID':'ID1', 'AIRCRAFT_TYPE':'AC1'},axis=1)\n",
    "c2 = coords_df[['FLIGHT_ID', 'SEGMENT_ID', 'AIRCRAFT_TYPE']].rename(\n",
    "    {'FLIGHT_ID':'FLIGHT_ID2', 'SEGMENT_ID':'ID2', 'AIRCRAFT_TYPE':'AC2'},axis=1)\n",
    "\n",
    "df = df.merge(c1, how='left').merge(c2, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df['FLIGHT_ID'] = coords_df['FLIGHT_ID'].apply(str) + '_id'\n",
    "df['FLIGHT_ID1'] = df['FLIGHT_ID1'].apply(str) + '_id'\n",
    "df['FLIGHT_ID2'] = df['FLIGHT_ID2'].apply(str) + '_id'\n",
    "coords_df = coords_df[coords_df.FLIGHT_ID.isin(df.FLIGHT_ID1.to_list() + df.FLIGHT_ID2.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df.to_parquet('coords.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('pairs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.ID2 == 2557313].lon2.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coords_df[coords_df.SEGMENT_ID == 2557313].longitude.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
